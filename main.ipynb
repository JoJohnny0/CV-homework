{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22152e7a",
   "metadata": {},
   "source": [
    "# Efficient Anomaly Detection in Industrial Images using Transformers with Dynamic Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7232d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from modules import data, globals, vtae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495213c5",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset: Literal['MVTech', 'BTAD'] = 'MVTech'\n",
    "product: data.ProductType = 'bottle'\n",
    "resize_dim: int = 550\n",
    "crop_dim: int = 512\n",
    "\n",
    "# Model\n",
    "patch_side: int = 64\n",
    "latent_channels: int = 8\n",
    "heads: int = 8\n",
    "depth: int = 6\n",
    "caps_per_patch: int = 64\n",
    "caps_dim: int = 8\n",
    "caps_iterations: int = 3\n",
    "ff_dim: int = 1024\n",
    "mdn_components: int = 150\n",
    "noise: float = 0.2\n",
    "loss_weights: tuple[float, float, float] = (5., 0.5, 1.)\n",
    "lr: float = 1e-4\n",
    "weight_decay: float = 1e-4\n",
    "use_dytanh: bool = False\n",
    "\n",
    "# Training\n",
    "epochs: int = 400\n",
    "batch_size: int = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43871876",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader: DataLoader[tuple[torch.Tensor]]\n",
    "val_loader: DataLoader[tuple[torch.Tensor]]\n",
    "test_loader: DataLoader[tuple[torch.Tensor, torch.Tensor]]\n",
    "\n",
    "train_loader, val_loader, test_loader = data.get_loaders(dataset,\n",
    "                                                         product,\n",
    "                                                         crop_dim = (crop_dim, crop_dim),\n",
    "                                                         resize_dim = (resize_dim, resize_dim),\n",
    "                                                         batch_size = batch_size\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad16a6c",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92364042",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: vtae.VTAE = vtae.VTAE(image_shape = (3, crop_dim, crop_dim),\n",
    "                             patch_shape = (patch_side, patch_side),\n",
    "                             latent_channels = latent_channels,\n",
    "                             heads = heads,\n",
    "                             depth = depth,\n",
    "                             caps_per_patch = caps_per_patch,\n",
    "                             caps_dim = caps_dim,\n",
    "                             caps_iterations = caps_iterations,\n",
    "                             ff_dim = ff_dim,\n",
    "                             mdn_components = mdn_components,\n",
    "                             noise = noise,\n",
    "                             loss_weights = loss_weights,\n",
    "                             lr = lr,\n",
    "                             weight_decay = weight_decay,\n",
    "                             use_dytanh = use_dytanh\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8861fae5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping: EarlyStopping = EarlyStopping(monitor = 'val_combined_loss', patience = 10)\n",
    "model_checkpoint: ModelCheckpoint = ModelCheckpoint(monitor = 'val_combined_loss',\n",
    "                                                    dirpath = globals.CHECKPOINT_DIR / dataset / product,\n",
    "                                                    save_top_k = 1\n",
    "                                                    )\n",
    "\n",
    "# Logger\n",
    "norm_str: str = \"dytanh\" if use_dytanh else \"layernorm\"\n",
    "logger: TensorBoardLogger = TensorBoardLogger(globals.LOG_DIR, name = f\"{dataset}_{product}_{norm_str}\")\n",
    "\n",
    "# Train the model\n",
    "trainer: Trainer = Trainer(max_epochs = epochs,\n",
    "                           callbacks = [early_stopping, model_checkpoint],\n",
    "                           precision = '16-mixed',\n",
    "                           log_every_n_steps = len(train_loader),\n",
    "                           logger = logger\n",
    "                           )\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148fc10",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6517a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
